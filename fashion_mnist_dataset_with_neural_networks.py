# -*- coding: utf-8 -*-
"""Fashion MNIST dataset with Neural Networks.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1wmA-ZOeM7bhOwwQyIQ-DD_t6CjIPCSgL
"""

import tensorflow as tf
print(tf.__version__)

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Flatten, Softmax

# Build the Sequential feedforward neural network model
model = Sequential([Flatten(input_shape = (28,28))])
model.add(Dense(16, activation = 'relu'))
model.add(Dense(16, activation = 'relu'))
model.add(Dense(10, activation = 'softmax'))

# Print the model summary
model.summary()

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D

# Build the Sequential convolutional neural network model
model1 = Sequential([
                    Conv2D(16, (3,3), activation = 'relu', input_shape = (28,28,1)),
                    MaxPooling2D((3,3)),
                    Flatten(),
                   Dense(10, activation = 'softmax')
])

# Define the model optimizer, loss function and metrics
opt = tf.keras.optimizers.Adam(learning_rate = 0.05)
acc = tf.keras.metrics.SparseCategoricalAccuracy()
mae = tf.keras.metrics.MeanAbsoluteError()

model1.compile(optimizer = opt,
             loss = 'sparse_categorical_crossentropy',
             metrics = [acc, mae])

# Print the resulting model attributes
print(model1.loss)
print(model1.optimizer)
print(model1.metrics)
print(model1.optimizer.lr)

from tensorflow.keras.preprocessing import image
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd

# Load the Fashion-MNIST dataset

fashion_mnist_data = tf.keras.datasets.fashion_mnist
(train_images, train_labels), (test_images, test_labels) = fashion_mnist_data.load_data()

# Print the shape of the training data
train_images.shape

# Define the labels

labels = [
    'T-shirt/top',
    'Trouser',
    'Pullover',
    'Dress',
    'Coat',
    'Sandal',
    'Shirt',
    'Sneaker',
    'Bag',
    'Ankle boot'
]
print(train_labels[0])

# Rescale the image values so that they lie in between 0 and 1.
train_images = train_images/255.0
test_images = test_images/255.0

# Display one of the images
i = 0
img = train_images[i, :, :]
plt.imshow(img)
plt.show()
print(f'labels    {labels[train_labels[i]]}')

# Fit the model

history = model1.fit(train_images[...,np.newaxis], train_labels, epochs = 8, batch_size = 256)

# Load the history into a pandas Dataframe
df = pd.DataFrame(history.history)
df.head()

# Make a plot for the loss
epoch = list(df.index)
epoch = [x + 1 for x in epoch]
losses = df['loss']
plt.plot(epoch, losses)
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.show()

loss, accuracy, mae = model1.evaluate(test_images[..., np.newaxis], test_labels)

print(loss)

print(accuracy)

print(mae)

predictions = model.predict(test_images[..., np.newaxis])

print(predictions)

